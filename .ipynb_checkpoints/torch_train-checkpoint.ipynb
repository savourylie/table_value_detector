{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from glob import glob\n",
    "from scipy import misc\n",
    "\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# from torchvision import models\n",
    "# from torchvision.models.vgg import VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TableDataset(Dataset):\n",
    "    \"\"\"The training table dataset.\n",
    "    \"\"\"\n",
    "    def __init__(self, x_path=None, y_path=None):\n",
    "        if x_path is None or y_path is None:\n",
    "            raise ValueError(\"No data source specified.\")\n",
    "        \n",
    "        x_filenames = glob(x_path + '*.png')\n",
    "        y_filenames = glob(y_path + '*.png')\n",
    "        \n",
    "        self.x_data = [torch.from_numpy(misc.imread(filename)) for filename in x_filenames]\n",
    "        self.y_data = [torch.from_numpy(misc.imread(filename)) for filename in y_filenames]\n",
    "        self.len = len(self.x_data)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TableDataset('/Users/calvinku/Dropbox/ThoroughAI/Side Projects/YangZhe/data/cell01/',\n",
    "                       '/Users/calvinku/Dropbox/ThoroughAI/Side Projects/YangZhe/data/xu_label_cell01/')\n",
    "\n",
    "train_loader = DataLoader(dataset=dataset,\n",
    "                         batch_size=1,\n",
    "                         shuffle=True,\n",
    "                         num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[255, 255, 255],\n",
      "          [255, 255, 255],\n",
      "          [255, 255, 255],\n",
      "          ...,\n",
      "          [255, 255, 255],\n",
      "          [255, 255, 255],\n",
      "          [255, 255, 255]],\n",
      "\n",
      "         [[255, 255, 255],\n",
      "          [255, 255, 255],\n",
      "          [255, 255, 255],\n",
      "          ...,\n",
      "          [255, 255, 255],\n",
      "          [255, 255, 255],\n",
      "          [255, 255, 255]],\n",
      "\n",
      "         [[255, 255, 255],\n",
      "          [255, 255, 255],\n",
      "          [255, 255, 255],\n",
      "          ...,\n",
      "          [255, 255, 255],\n",
      "          [255, 255, 255],\n",
      "          [255, 255, 255]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[255, 255, 255],\n",
      "          [255, 255, 255],\n",
      "          [255, 255, 255],\n",
      "          ...,\n",
      "          [255, 255, 255],\n",
      "          [255, 255, 255],\n",
      "          [255, 255, 255]],\n",
      "\n",
      "         [[255, 255, 255],\n",
      "          [255, 255, 255],\n",
      "          [255, 255, 255],\n",
      "          ...,\n",
      "          [255, 255, 255],\n",
      "          [255, 255, 255],\n",
      "          [255, 255, 255]],\n",
      "\n",
      "         [[255, 255, 255],\n",
      "          [255, 255, 255],\n",
      "          [255, 255, 255],\n",
      "          ...,\n",
      "          [255, 255, 255],\n",
      "          [255, 255, 255],\n",
      "          [255, 255, 255]]]], dtype=torch.uint8)\n",
      "tensor([[[[255, 255, 255],\n",
      "          [255, 255, 255],\n",
      "          [255, 255, 255],\n",
      "          ...,\n",
      "          [255, 255, 255],\n",
      "          [255, 255, 255],\n",
      "          [255, 255, 255]],\n",
      "\n",
      "         [[255, 255, 255],\n",
      "          [255, 255, 255],\n",
      "          [255, 255, 255],\n",
      "          ...,\n",
      "          [255, 255, 255],\n",
      "          [255, 255, 255],\n",
      "          [255, 255, 255]],\n",
      "\n",
      "         [[255, 255, 255],\n",
      "          [255, 255, 255],\n",
      "          [255, 255, 255],\n",
      "          ...,\n",
      "          [255, 255, 255],\n",
      "          [255, 255, 255],\n",
      "          [255, 255, 255]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[255, 255, 255],\n",
      "          [255, 255, 255],\n",
      "          [255, 255, 255],\n",
      "          ...,\n",
      "          [255, 255, 255],\n",
      "          [255, 255, 255],\n",
      "          [255, 255, 255]],\n",
      "\n",
      "         [[255, 255, 255],\n",
      "          [255, 255, 255],\n",
      "          [255, 255, 255],\n",
      "          ...,\n",
      "          [255, 255, 255],\n",
      "          [255, 255, 255],\n",
      "          [255, 255, 255]],\n",
      "\n",
      "         [[255, 255, 255],\n",
      "          [255, 255, 255],\n",
      "          [255, 255, 255],\n",
      "          ...,\n",
      "          [255, 255, 255],\n",
      "          [255, 255, 255],\n",
      "          [255, 255, 255]]]], dtype=torch.uint8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-8:\n",
      "  File \"/Users/calvinku/anaconda/envs/pytorch/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "Process Process-7:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/calvinku/anaconda/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/calvinku/anaconda/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/calvinku/anaconda/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/calvinku/anaconda/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/calvinku/anaconda/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/Users/calvinku/anaconda/envs/pytorch/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if timeout < 0 or not self._poll(timeout):\n",
      "  File \"/Users/calvinku/anaconda/envs/pytorch/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/Users/calvinku/anaconda/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/Users/calvinku/anaconda/envs/pytorch/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/Users/calvinku/anaconda/envs/pytorch/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if timeout < 0 or not self._poll(timeout):\n",
      "  File \"/Users/calvinku/anaconda/envs/pytorch/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/Users/calvinku/anaconda/envs/pytorch/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/Users/calvinku/anaconda/envs/pytorch/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/Users/calvinku/anaconda/envs/pytorch/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/Users/calvinku/anaconda/envs/pytorch/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "Exception ignored in: <bound method _DataLoaderIter.__del__ of <torch.utils.data.dataloader._DataLoaderIter object at 0x417bab748>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/calvinku/anaconda/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 399, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/Users/calvinku/anaconda/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 378, in _shutdown_workers\n",
      "    self.worker_result_queue.get()\n",
      "  File \"/Users/calvinku/anaconda/envs/pytorch/lib/python3.6/multiprocessing/queues.py\", line 345, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/Users/calvinku/anaconda/envs/pytorch/lib/python3.6/site-packages/torch/multiprocessing/reductions.py\", line 167, in rebuild_storage_filename\n",
      "    storage = cls._new_shared_filename(manager, handle, size)\n",
      "  File \"/Users/calvinku/anaconda/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 227, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 13108) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/calvinku/anaconda/envs/pytorch/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-16-1d27b624802c>\", line 3, in <module>\n",
      "    print(inputs)\n",
      "  File \"/Users/calvinku/anaconda/envs/pytorch/lib/python3.6/site-packages/torch/tensor.py\", line 57, in __repr__\n",
      "    return torch._tensor_str._str(self)\n",
      "  File \"/Users/calvinku/anaconda/envs/pytorch/lib/python3.6/site-packages/torch/_tensor_str.py\", line 256, in _str\n",
      "    formatter = _Formatter(get_summarized_data(self) if summarize else self)\n",
      "  File \"/Users/calvinku/anaconda/envs/pytorch/lib/python3.6/site-packages/torch/_tensor_str.py\", line 78, in __init__\n",
      "    value_str = '{}'.format(value)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/calvinku/anaconda/envs/pytorch/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 1821, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/calvinku/anaconda/envs/pytorch/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n",
      "    if self.run_code(code, result):\n",
      "  File \"/Users/calvinku/anaconda/envs/pytorch/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2898, in run_code\n",
      "    self.showtraceback()\n",
      "  File \"/Users/calvinku/anaconda/envs/pytorch/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 1824, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"/Users/calvinku/anaconda/envs/pytorch/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1412, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"/Users/calvinku/anaconda/envs/pytorch/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1317, in structured_traceback\n",
      "    if mode in self.verbose_modes:\n",
      "  File \"/Users/calvinku/anaconda/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 227, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 12938) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/calvinku/anaconda/envs/pytorch/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 1821, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'RuntimeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/calvinku/anaconda/envs/pytorch/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1132, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/Users/calvinku/anaconda/envs/pytorch/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/calvinku/anaconda/envs/pytorch/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/Users/calvinku/anaconda/envs/pytorch/lib/python3.6/inspect.py\", line 1453, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/Users/calvinku/anaconda/envs/pytorch/lib/python3.6/inspect.py\", line 1415, in getframeinfo\n",
      "    lines, lnum = findsource(frame)\n",
      "  File \"/Users/calvinku/anaconda/envs/pytorch/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 229, in findsource\n",
      "    if pmatch(lines[lnum]):\n",
      "  File \"/Users/calvinku/anaconda/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 227, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 13014) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.\n"
     ]
    }
   ],
   "source": [
    "for i, data in enumerate(train_loader, 0):\n",
    "    inputs, labels = data\n",
    "    print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FCN32s(nn.Module):\n",
    "\n",
    "    def __init__(self, pretrained_net, n_class):\n",
    "        super().__init__()\n",
    "        self.n_class = n_class\n",
    "        self.pretrained_net = pretrained_net\n",
    "        self.relu    = nn.ReLU(inplace=True)\n",
    "        self.deconv1 = nn.ConvTranspose2d(512, 512, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
    "        self.bn1     = nn.BatchNorm2d(512)\n",
    "        self.deconv2 = nn.ConvTranspose2d(512, 256, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
    "        self.bn2     = nn.BatchNorm2d(256)\n",
    "        self.deconv3 = nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
    "        self.bn3     = nn.BatchNorm2d(128)\n",
    "        self.deconv4 = nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
    "        self.bn4     = nn.BatchNorm2d(64)\n",
    "        self.deconv5 = nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
    "        self.bn5     = nn.BatchNorm2d(32)\n",
    "        self.classifier = nn.Conv2d(32, n_class, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.pretrained_net(x)\n",
    "        x5 = output['x5']  # size=(N, 512, x.H/32, x.W/32)\n",
    "\n",
    "        x = self.bn1(self.relu(self.deconv1(x5)))     # size=(N, 512, x.H/16, x.W/16)\n",
    "        x = self.bn2(self.relu(self.deconv2(x)))  # size=(N, 256, x.H/8, x.W/8)\n",
    "        x = self.bn3(self.relu(self.deconv3(x)))  # size=(N, 128, x.H/4, x.W/4)\n",
    "        x = self.bn4(self.relu(self.deconv4(x)))  # size=(N, 64, x.H/2, x.W/2)\n",
    "        x = self.bn5(self.relu(self.deconv5(x)))  # size=(N, 32, x.H, x.W)\n",
    "        score = self.classifier(score)                    # size=(N, n_class, x.H/1, x.W/1)\n",
    "\n",
    "        return score  # size=(N, n_class, x.H/1, x.W/1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class VGGNet(VGG):\n",
    "    def __init__(self, pretrained=True, model='vgg16', requires_grad=True, remove_fc=True, show_params=False):\n",
    "        super().__init__(make_layers(cfg[model]))\n",
    "        self.ranges = ranges[model]\n",
    "\n",
    "        if pretrained:\n",
    "            exec(\"self.load_state_dict(models.%s(pretrained=True).state_dict())\" % model)\n",
    "\n",
    "        if not requires_grad:\n",
    "            for param in super().parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "        if remove_fc:  # delete redundant fully-connected layer params, can save memory\n",
    "            del self.classifier\n",
    "\n",
    "        if show_params:\n",
    "            for name, param in self.named_parameters():\n",
    "                print(name, param.size())\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = {}\n",
    "\n",
    "        # get the output of each maxpooling layer (5 maxpool in VGG net)\n",
    "        for idx in range(len(self.ranges)):\n",
    "            for layer in range(self.ranges[idx][0], self.ranges[idx][1]):\n",
    "                x = self.features[layer](x)\n",
    "            output[\"x%d\"%(idx+1)] = x\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ranges = {\n",
    "    'vgg11': ((0, 3), (3, 6),  (6, 11),  (11, 16), (16, 21)),\n",
    "    'vgg13': ((0, 5), (5, 10), (10, 15), (15, 20), (20, 25)),\n",
    "    'vgg16': ((0, 5), (5, 10), (10, 17), (17, 24), (24, 31)),\n",
    "    'vgg19': ((0, 5), (5, 10), (10, 19), (19, 28), (28, 37))\n",
    "}\n",
    "\n",
    "# cropped version from https://github.com/pytorch/vision/blob/master/torchvision/models/vgg.py\n",
    "cfg = {\n",
    "    'vgg11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'vgg13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'vgg16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "    'vgg19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
    "}\n",
    "\n",
    "def make_layers(cfg, batch_norm=False):\n",
    "    layers = []\n",
    "    in_channels = 3\n",
    "    for v in cfg:\n",
    "        if v == 'M':\n",
    "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "        else:\n",
    "            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
    "            if batch_norm:\n",
    "                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
    "            else:\n",
    "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
    "            in_channels = v\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    batch_size, n_class, h, w = 10, 20, 160, 160\n",
    "\n",
    "    # test output size\n",
    "    vgg_model = VGGNet(requires_grad=True)\n",
    "    input = torch.autograd.Variable(torch.randn(batch_size, 3, 224, 224))\n",
    "    output = vgg_model(input)\n",
    "    assert output['x5'].size() == torch.Size([batch_size, 512, 7, 7])\n",
    "\n",
    "    fcn_model = FCN32s(pretrained_net=vgg_model, n_class=n_class)\n",
    "    input = torch.autograd.Variable(torch.randn(batch_size, 3, h, w))\n",
    "    output = fcn_model(input)\n",
    "    assert output.size() == torch.Size([batch_size, n_class, h, w])\n",
    "\n",
    "    fcn_model = FCN16s(pretrained_net=vgg_model, n_class=n_class)\n",
    "    input = torch.autograd.Variable(torch.randn(batch_size, 3, h, w))\n",
    "    output = fcn_model(input)\n",
    "    assert output.size() == torch.Size([batch_size, n_class, h, w])\n",
    "\n",
    "    fcn_model = FCN8s(pretrained_net=vgg_model, n_class=n_class)\n",
    "    input = torch.autograd.Variable(torch.randn(batch_size, 3, h, w))\n",
    "    output = fcn_model(input)\n",
    "    assert output.size() == torch.Size([batch_size, n_class, h, w])\n",
    "\n",
    "    fcn_model = FCNs(pretrained_net=vgg_model, n_class=n_class)\n",
    "    input = torch.autograd.Variable(torch.randn(batch_size, 3, h, w))\n",
    "    output = fcn_model(input)\n",
    "    assert output.size() == torch.Size([batch_size, n_class, h, w])\n",
    "\n",
    "    print(\"Pass size check\")\n",
    "\n",
    "    # test a random batch, loss should decrease\n",
    "    fcn_model = FCNs(pretrained_net=vgg_model, n_class=n_class)\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.SGD(fcn_model.parameters(), lr=1e-3, momentum=0.9)\n",
    "    input = torch.autograd.Variable(torch.randn(batch_size, 3, h, w))\n",
    "    y = torch.autograd.Variable(torch.randn(batch_size, n_class, h, w), requires_grad=False)\n",
    "    for iter in range(10):\n",
    "        optimizer.zero_grad()\n",
    "        output = fcn_model(input)\n",
    "        output = nn.functional.sigmoid(output)\n",
    "        loss = criterion(output, y)\n",
    "        loss.backward()\n",
    "        print(\"iter{}, loss {}\".format(iter, loss.data[0]))\n",
    "        optimizer.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
