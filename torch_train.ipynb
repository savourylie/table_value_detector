{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from glob import glob\n",
    "from imageio import imread\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TableDataset(Dataset):\n",
    "    \"\"\"The training table dataset.\n",
    "    \"\"\"\n",
    "    def __init__(self, x_path=None, y_path=None):\n",
    "        if x_path is None or y_path is None:\n",
    "            raise ValueError(\"No data source specified.\")\n",
    "        \n",
    "        x_filenames = glob(x_path + '*.png')\n",
    "        y_filenames = glob(y_path + '*.png')\n",
    "        \n",
    "        self.x_data = [torch.from_numpy(imread(filename).transpose(2, 0, 1)) for filename in x_filenames]\n",
    "        self.y_data = [torch.from_numpy(imread(filename).reshape(1, *imread(filename).shape)) for filename in y_filenames]\n",
    "        self.len = len(self.x_data)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = TableDataset('/Users/calvinku/Dropbox/ThoroughAI/Side Projects/YangZhe/data/cell01/',\n",
    "                       '/Users/calvinku/Dropbox/ThoroughAI/Side Projects/YangZhe/data/xu_label_cell01/')\n",
    "\n",
    "train_loader = DataLoader(dataset=dataset,\n",
    "                         batch_size=1,\n",
    "                         shuffle=True,\n",
    "                         num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(332, 1413, 3) (332, 1413)\n",
      "(3, 332, 1413) (1, 332, 1413)\n"
     ]
    }
   ],
   "source": [
    "img = imread('/Users/calvinku/Dropbox/ThoroughAI/Side Projects/YangZhe/data/cell01/1.png')\n",
    "label = imread('/Users/calvinku/Dropbox/ThoroughAI/Side Projects/YangZhe/data/xu_label_cell01/1.png')\n",
    "\n",
    "print(img.shape, label.shape)\n",
    "print(img.transpose(2, 0, 1).shape, label.reshape(1, *label.shape).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FCN(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()        \n",
    "        self.conv11 = nn.Conv2d(3, 64, 3, stride=1, padding=0)\n",
    "        self.conv12 = nn.Conv2d(64, 64, 3, stride=1, padding=0)\n",
    "        self.pool1 = nn.MaxPool2d(2, stride=1)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.conv21 = nn.Conv2d(64, 128, 3, stride=1, padding=0)\n",
    "        self.conv22 = nn.Conv2d(128, 128, 3, stride=1, padding=0)\n",
    "        self.pool2 = nn.MaxPool2d(2, stride=1)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.conv31 = nn.Conv2d(128, 512, 3, stride=1, padding=0)\n",
    "        self.conv32 = nn.Conv2d(512, 512, 3, stride=1, padding=0)\n",
    "        self.pool3 = nn.MaxPool2d(2, stride=1)\n",
    "        self.relu3 = nn.ReLU(inplace=True)\n",
    "                \n",
    "        self.deconv11 = nn.ConvTranspose2d(512, 128, kernel_size=3, stride=1, padding=0)\n",
    "        self.deconv12 = nn.ConvTranspose2d(128, 128, kernel_size=3, stride=1, padding=0)\n",
    "        self.deconv13 = nn.ConvTranspose2d(128, 128, kernel_size=2, stride=1, padding=0)\n",
    "        self.relu4 = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.deconv21 = nn.ConvTranspose2d(128, 64, kernel_size=3, stride=1, padding=0)\n",
    "        self.deconv22 = nn.ConvTranspose2d(64, 64, kernel_size=3, stride=1, padding=0)\n",
    "        self.deconv23 = nn.ConvTranspose2d(64, 64, kernel_size=2, stride=1, padding=0)\n",
    "        self.relu5 = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.deconv31 = nn.ConvTranspose2d(64, 1, kernel_size=3, stride=1, padding=0)\n",
    "        self.deconv32 = nn.ConvTranspose2d(1, 1, kernel_size=3, stride=1, padding=0)\n",
    "        self.deconv33 = nn.ConvTranspose2d(1, 1, kernel_size=2, stride=1, padding=0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu1(self.pool1(self.conv12(self.conv11(x))))\n",
    "        print(x.shape)\n",
    "#         x = self.relu2(self.pool2(self.conv22(self.conv21(x))))\n",
    "#         x = self.relu3(self.pool3(self.conv32(self.conv31(x))))\n",
    "        \n",
    "#         x = self.relu4(self.unpool1(self.deconv12(self.deconv11(x))))\n",
    "#         x = self.relu5(self.unpool2(self.deconv22(self.deconv21(x))))\n",
    "        x = self.deconv33(self.deconv32(self.deconv31(x)))\n",
    "        print(x.shape)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FCN32s(nn.Module):\n",
    "\n",
    "    def __init__(self, pretrained_net, n_class):\n",
    "        super().__init__()\n",
    "        self.n_class = n_class\n",
    "        self.pretrained_net = pretrained_net\n",
    "        self.relu    = nn.ReLU(inplace=True)\n",
    "        self.deconv1 = nn.ConvTranspose2d(512, 512, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
    "        self.bn1     = nn.BatchNorm2d(512)\n",
    "        self.deconv2 = nn.ConvTranspose2d(512, 256, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
    "        self.bn2     = nn.BatchNorm2d(256)\n",
    "        self.deconv3 = nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
    "        self.bn3     = nn.BatchNorm2d(128)\n",
    "        self.deconv4 = nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
    "        self.bn4     = nn.BatchNorm2d(64)\n",
    "        self.deconv5 = nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
    "        self.bn5     = nn.BatchNorm2d(32)\n",
    "        self.classifier = nn.Conv2d(32, n_class, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.pretrained_net(x)\n",
    "        x5 = output['x5']  # size=(N, 512, x.H/32, x.W/32)\n",
    "        print(x5.shape)\n",
    "        x = self.bn1(self.relu(self.deconv1(x5)))     # size=(N, 512, x.H/16, x.W/16)\n",
    "        print(x.shape)\n",
    "        x = self.bn2(self.relu(self.deconv2(x)))  # size=(N, 256, x.H/8, x.W/8)\n",
    "        print(x.shape)\n",
    "        x = self.bn3(self.relu(self.deconv3(x)))  # size=(N, 128, x.H/4, x.W/4)\n",
    "        print(x.shape)\n",
    "        x = self.bn4(self.relu(self.deconv4(x)))  # size=(N, 64, x.H/2, x.W/2)\n",
    "        print(x.shape)\n",
    "        x = self.bn5(self.relu(self.deconv5(x)))  # size=(N, 32, x.H, x.W)\n",
    "        print(x.shape)\n",
    "        x = self.classifier(x)                   # size=(N, n_class, x.H/1, x.W/1)\n",
    "        print(x.shape)\n",
    "\n",
    "        return x  # size=(N, n_class, x.H/1, x.W/1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape: torch.Size([1, 3, 556, 1135]), y shape: torch.Size([1, 1, 556, 1135])\n",
      "torch.Size([1, 64, 551, 1130])\n",
      "torch.Size([1, 1, 556, 1135])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/calvinku/anaconda/envs/pytorch/lib/python3.6/site-packages/torch/nn/functional.py:1006: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/Users/calvinku/anaconda/envs/pytorch/lib/python3.6/site-packages/ipykernel/__main__.py:41: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter<built-in function iter>, loss -75.0948715209961\n",
      "x shape: torch.Size([1, 3, 1277, 1604]), y shape: torch.Size([1, 1, 1277, 1604])\n",
      "torch.Size([1, 64, 1272, 1599])\n",
      "torch.Size([1, 1, 1277, 1604])\n",
      "iter<built-in function iter>, loss -5660.197265625\n",
      "x shape: torch.Size([1, 3, 246, 1403]), y shape: torch.Size([1, 1, 246, 1403])\n",
      "torch.Size([1, 64, 241, 1398])\n",
      "torch.Size([1, 1, 246, 1403])\n",
      "iter<built-in function iter>, loss -5374.37548828125\n",
      "x shape: torch.Size([1, 3, 891, 1536]), y shape: torch.Size([1, 1, 891, 1536])\n",
      "torch.Size([1, 64, 886, 1531])\n",
      "torch.Size([1, 1, 891, 1536])\n",
      "iter<built-in function iter>, loss -5545.23095703125\n",
      "x shape: torch.Size([1, 3, 406, 1101]), y shape: torch.Size([1, 1, 406, 1101])\n",
      "torch.Size([1, 64, 401, 1096])\n",
      "torch.Size([1, 1, 406, 1101])\n",
      "iter<built-in function iter>, loss -4652.00439453125\n",
      "x shape: torch.Size([1, 3, 495, 1570]), y shape: torch.Size([1, 1, 495, 1570])\n",
      "torch.Size([1, 64, 490, 1565])\n",
      "torch.Size([1, 1, 495, 1570])\n",
      "iter<built-in function iter>, loss -5360.15234375\n",
      "x shape: torch.Size([1, 3, 575, 1391]), y shape: torch.Size([1, 1, 575, 1391])\n",
      "torch.Size([1, 64, 570, 1386])\n",
      "torch.Size([1, 1, 575, 1391])\n",
      "iter<built-in function iter>, loss -4896.767578125\n",
      "x shape: torch.Size([1, 3, 631, 815]), y shape: torch.Size([1, 1, 631, 815])\n",
      "torch.Size([1, 64, 626, 810])\n",
      "torch.Size([1, 1, 631, 815])\n",
      "iter<built-in function iter>, loss -6426.52880859375\n",
      "x shape: torch.Size([1, 3, 687, 1283]), y shape: torch.Size([1, 1, 687, 1283])\n",
      "torch.Size([1, 64, 682, 1278])\n",
      "torch.Size([1, 1, 687, 1283])\n",
      "iter<built-in function iter>, loss -4782.59326171875\n",
      "x shape: torch.Size([1, 3, 585, 1587]), y shape: torch.Size([1, 1, 585, 1587])\n",
      "torch.Size([1, 64, 580, 1582])\n",
      "torch.Size([1, 1, 585, 1587])\n",
      "iter<built-in function iter>, loss -5054.05322265625\n",
      "x shape: torch.Size([1, 3, 1355, 1401]), y shape: torch.Size([1, 1, 1355, 1401])\n",
      "torch.Size([1, 64, 1350, 1396])\n",
      "torch.Size([1, 1, 1355, 1401])\n",
      "iter<built-in function iter>, loss -6265.4716796875\n",
      "x shape: torch.Size([1, 3, 829, 1587]), y shape: torch.Size([1, 1, 829, 1587])\n",
      "torch.Size([1, 64, 824, 1582])\n",
      "torch.Size([1, 1, 829, 1587])\n",
      "iter<built-in function iter>, loss -5308.10693359375\n",
      "x shape: torch.Size([1, 3, 354, 1419]), y shape: torch.Size([1, 1, 354, 1419])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-16:\n",
      "Process Process-15:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/calvinku/anaconda/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/calvinku/anaconda/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/calvinku/anaconda/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/calvinku/anaconda/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/calvinku/anaconda/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/Users/calvinku/anaconda/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/Users/calvinku/anaconda/envs/pytorch/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if timeout < 0 or not self._poll(timeout):\n",
      "  File \"/Users/calvinku/anaconda/envs/pytorch/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if timeout < 0 or not self._poll(timeout):\n",
      "  File \"/Users/calvinku/anaconda/envs/pytorch/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/Users/calvinku/anaconda/envs/pytorch/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/Users/calvinku/anaconda/envs/pytorch/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/Users/calvinku/anaconda/envs/pytorch/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/Users/calvinku/anaconda/envs/pytorch/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/Users/calvinku/anaconda/envs/pytorch/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/Users/calvinku/anaconda/envs/pytorch/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/calvinku/anaconda/envs/pytorch/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-884d775f4acb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"x shape: {}, y shape: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfcn_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/calvinku/anaconda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-ac35acb52540>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv12\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv11\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m#         x = self.relu2(self.pool2(self.conv22(self.conv21(x))))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/calvinku/anaconda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/calvinku/anaconda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/pooling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    140\u001b[0m         return F.max_pool2d(input, self.kernel_size, self.stride,\n\u001b[1;32m    141\u001b[0m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m                             self.return_indices)\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/calvinku/anaconda/envs/pytorch/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmax_pool2d\u001b[0;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[1;32m    394\u001b[0m     \u001b[0mSee\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaxPool2d\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdetails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m     \"\"\"\n\u001b[0;32m--> 396\u001b[0;31m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d_with_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mceil_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_indices\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torchvision import models\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    num_epochs = 3\n",
    "    \n",
    "#     # test output size\n",
    "#     vgg_model = VGGNet(requires_grad=True)\n",
    "#     input = torch.autograd.Variable(torch.randn(batch_size, 3, 224, 224))\n",
    "#     output = vgg_model(input)\n",
    "#     assert output['x5'].size() == torch.Size([batch_size, 512, 7, 7])\n",
    "\n",
    "#     fcn_model = FCN32s(pretrained_net=vgg_model, n_class=n_class)\n",
    "#     input = torch.autograd.Variable(torch.randn(batch_size, 3, h, w))\n",
    "#     output = fcn_model(input)\n",
    "#     assert output.size() == torch.Size([batch_size, n_class, h, w])\n",
    "\n",
    "#     print(\"Pass size check\")\n",
    "\n",
    "#     # test a random batch, loss should decrease\n",
    "\n",
    "#     pretrained_net = VGGNet()\n",
    "#     fcn_model = FCN32s(pretrained_net=pretrained_net, n_class=1)\n",
    "    fcn_model = FCN()\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.SGD(fcn_model.parameters(), lr=1e-3, momentum=0.9)\n",
    "\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        for i, data in enumerate(train_loader):\n",
    "            x, y = data\n",
    "            x, y = Variable(x.type(torch.FloatTensor), requires_grad=False), Variable(y.type(torch.FloatTensor), requires_grad=False)\n",
    "            \n",
    "            print(\"x shape: {}, y shape: {}\".format(x.shape, y.shape))\n",
    "            optimizer.zero_grad()\n",
    "            output = fcn_model(x)\n",
    "            output = nn.functional.sigmoid(output)\n",
    "            loss = criterion(output, y)\n",
    "            loss.backward()\n",
    "            print(\"iter{}, loss {}\".format(iter, loss.data[0]))\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
